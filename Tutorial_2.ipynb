{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin:\n",
    "Run the following line and ensure that it prints out something like\n",
    "```\n",
    "/home/ubuntu/<Your quest ID>/Tutorial-Series\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Tutorial-Series\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- <a href='#1.0'>Section 1 - Introduction</a>\n",
    "- <a href='#2.0'>Section 2 - The Process of Genome Assembly</a>\n",
    "    - <a href='#2.1'>Section 2.1 - Sequencing</a>\n",
    "    - <a href='#2.2'>Section 2.2 - Assembly on the Computer</a>\n",
    "    - <a href='#2.3'>Section 2.3 - Running Velvet</a>\n",
    "- <a href='#3.0'>Section 3 - Visualizing our Assembly</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Genome Assembly\n",
    "## <a id='1.0'>Section 1 - Introduction</a>\n",
    "\n",
    "In Tutorial 1 we learned how to navigate around Jupyter Notebooks as well as explored some basic Command Line arguments. We also learned about the BLAST algorithm and how we can search for similarities between sequences. We finished the tutorial by BLASTing a viral protein against the genome for an E. coli strain named O157:H7. Surprisingly, we found that there were some similar proteins in the bacterial genome!\n",
    "\n",
    "In this tutorial, we'll be taking some unknown E. coli reads that we found and we'll try to identify which strain they might've come from by walking through the process of genome assembly and searching with BLAST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2.0'>Section 2 - The Process of Genome Assembly</a>\n",
    "\n",
    "Genome assembly is a large part of bioinformatics. It's how we take physical DNA sequences and store them in a computer readable format. Genome assembly usually refers to two specific processes, sequencing and computational assembly. Sequencing is the wet lab component of taking our physical DNA and storing it into a computer, while assembly further processes that data into a genome that could be further investigated or uploaded to NCBI.\n",
    "\n",
    "<img src='img/tut02/assembly-overview.PNG'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2.1'>Section 2.1 - Sequencing</a>\n",
    "\n",
    "Recent advances in bioinformatics are all thanks to the rapid developments in sequencing technology! These Next-Gen Sequencing technologies allow us to cheaply and rapidly read short segments of DNA or RNA. This in turn allows for researchers to cover more sections of a genome to generate higher quality genome reconstructions. Older sequencing technologies, mainly Sanger sequencing have only been able to read a single sequence that would be 600 - 1200 base pairs long. With Next-Gen Sequencing we're often able to get enough reads to cover an entire genome 50 times!\n",
    "\n",
    "<img src='img/tut02/shotgun_sequencing.PNG'></img>\n",
    "\n",
    "Typically when people talk about sequencing a genome they're referring to Whole Genome Shotgun Sequencing. This involves shearing our sample DNA into tiny chunks. These chunks, invidually, are simpler to sequence, allowing modern sequencers to read multiple chunks at the same time! After all of that, all of the read sequences are stored in `.fastq` files for further processing. In the field, whenever you hear someone talk about reads, they're most likely talking about the `.fastq` that was produced from the sequencer. Below is a picture of what an Illumina Sequencer looks like...\n",
    "\n",
    "<img src='img/tut02/Sequencer.PNG'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2.2'>Section 2.2 - Assembly on the Computer</a>\n",
    "\n",
    "So, now we have our `raw_reads1.fastq` file and we want to assemble it into a single sequence. This is where the power of Computer Science comes in! To do this, we're going to use a famous assembly program called Velvet.\n",
    "\n",
    "There are a ton of intracacies involved in genome assembly, but we'll try to cover the major ideas. To piece together our reads we need to further slice our reads up, into fragments. The \"k\" in k-mers represents how many bases we have in our slices. For example, `ATGC` is a 5-mer, since it has five bases in it. By using k-mers, our computer can readily sort them and start building the sequences from there. The image below shows all of the 5-mers for two sets of reads.\n",
    "\n",
    "<img src='img/tut02/kmers.png'></img>\n",
    "\n",
    "Now, after collecting all of the k-mers we can overlap them until we can find the the longest sequences possible. We can stack the k-mers of our reads to build contigs and finally we can stack our contigs to build scaffolds.\n",
    "\n",
    "<img src='img/tut02/GenomeAssembly.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2.3'>Section 2.3 - Running Velvet</a>\n",
    "\n",
    "Now that we understand the process of genome assembly let's run our commands to assemble our `raw_reads1.fastq`...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000000] Reading FastQ file raw_reads1.fastq;\n",
      "[7.284250] 1257935 sequences found\n",
      "[7.284262] Done\n",
      "[8.277546] Reading read set file data/tut02/assembly/Sequences;\n",
      "[8.536103] 1257935 sequences found\n",
      "[9.853106] Done\n",
      "[9.853124] 1257935 sequences in total.\n",
      "[9.853176] Writing into roadmap file data/tut02/assembly/Roadmaps...\n",
      "[13.124403] Inputting sequences...\n",
      "[13.124417] Inputting sequence 0 / 1257935\n",
      "[51.210761] Inputting sequence 1000000 / 1257935\n",
      "[61.260348]  === Sequences loaded in 48.135962 s\n",
      "[61.292445] Done inputting sequences\n",
      "[61.292464] Destroying splay table\n",
      "[61.316316] Splay table destroyed\n"
     ]
    }
   ],
   "source": [
    "!velveth data/tut02/assembly 31 -short -fastq raw_reads1.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`velveth` sets the order for which k-mers will be read first. The other arguments specify that we're reading from a `.fastq` file type and that we want a k-mer size of 31 bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000001] Reading roadmap file data/tut02/assembly//Roadmaps\n",
      "[2.364279] 1257935 roadmaps read\n",
      "[2.364802] Creating insertion markers\n",
      "[2.716147] Ordering insertion markers\n",
      "[4.058660] Counting preNodes\n",
      "[4.266896] 2074211 preNodes counted, creating them now\n",
      "[9.323758] Sequence 1000000 / 1257935\n",
      "[10.483138] Adjusting marker info...\n",
      "[10.750601] Connecting preNodes\n",
      "[14.122816] Connecting 1000000 / 1257935\n",
      "[15.071025] Cleaning up memory\n",
      "[15.074082] Done creating preGraph\n",
      "[15.074087] Concatenation...\n",
      "[15.763336] Renumbering preNodes\n",
      "[15.763352] Initial preNode count 2074211\n",
      "[15.826490] Destroyed 1432820 preNodes\n",
      "[15.826504] Concatenation over!\n",
      "[15.826507] Clipping short tips off preGraph\n",
      "[15.913341] Concatenation...\n",
      "[16.015534] Renumbering preNodes\n",
      "[16.015548] Initial preNode count 641391\n",
      "[16.064066] Destroyed 45511 preNodes\n",
      "[16.064077] Concatenation over!\n",
      "[16.064079] 24400 tips cut off\n",
      "[16.064081] 595880 nodes left\n",
      "[16.064137] Writing into pregraph file data/tut02/assembly//PreGraph...\n",
      "[17.591328] Reading read set file data/tut02/assembly//Sequences;\n",
      "[17.857753] 1257935 sequences found\n",
      "[19.181017] Done\n",
      "[22.374455] Reading pre-graph file data/tut02/assembly//PreGraph\n",
      "[22.375269] Graph has 595880 nodes and 1257935 sequences\n",
      "[23.063159] Scanning pre-graph file data/tut02/assembly//PreGraph for k-mers\n",
      "[23.189698] 12082443 kmers found\n",
      "[23.905210] Sorting kmer occurence table ... \n",
      "[27.816940] Sorting done.\n",
      "[27.816956] Computing acceleration table... \n",
      "[27.966953] Computing offsets... \n",
      "[28.031841] Ghost Threading through reads 0 / 1257935\n",
      "[81.796773] Ghost Threading through reads 1000000 / 1257935\n",
      "[95.763273]  === Ghost-Threaded in 67.731432 s\n",
      "[95.763290] Threading through reads 0 / 1257935\n",
      "[161.897181] Threading through reads 1000000 / 1257935\n",
      "[178.972595]  === Threaded in 83.209304 s\n",
      "[179.576304] Correcting graph with cutoff 0.200000\n",
      "[179.606488] Determining eligible starting points\n",
      "[180.260653] Done listing starting nodes\n",
      "[180.260667] Initializing todo lists\n",
      "[180.390284] Done with initilization\n",
      "[180.390299] Activating arc lookup table\n",
      "[180.652190] Done activating arc lookup table\n",
      "[180.724029] 10000 / 595880 nodes visited\n",
      "[180.820789] 20000 / 595880 nodes visited\n",
      "[180.921329] 30000 / 595880 nodes visited\n",
      "[181.032374] 40000 / 595880 nodes visited\n",
      "[181.166219] 50000 / 595880 nodes visited\n",
      "[181.287936] 60000 / 595880 nodes visited\n",
      "[181.406258] 70000 / 595880 nodes visited\n",
      "[181.523883] 80000 / 595880 nodes visited\n",
      "[181.650102] 90000 / 595880 nodes visited\n",
      "[181.771073] 100000 / 595880 nodes visited\n",
      "[181.898145] 110000 / 595880 nodes visited\n",
      "[182.035167] 120000 / 595880 nodes visited\n",
      "[182.161966] 130000 / 595880 nodes visited\n",
      "[182.284144] 140000 / 595880 nodes visited\n",
      "[182.408946] 150000 / 595880 nodes visited\n",
      "[182.542835] 160000 / 595880 nodes visited\n",
      "[182.675588] 170000 / 595880 nodes visited\n",
      "[182.804191] 180000 / 595880 nodes visited\n",
      "[182.926385] 190000 / 595880 nodes visited\n",
      "[183.048953] 200000 / 595880 nodes visited\n",
      "[183.172715] 210000 / 595880 nodes visited\n",
      "[183.302833] 220000 / 595880 nodes visited\n",
      "[183.437470] 230000 / 595880 nodes visited\n",
      "[183.576596] 240000 / 595880 nodes visited\n",
      "[183.715059] 250000 / 595880 nodes visited\n",
      "[183.853124] 260000 / 595880 nodes visited\n",
      "[183.989534] 270000 / 595880 nodes visited\n",
      "[184.122955] 280000 / 595880 nodes visited\n",
      "[184.260627] 290000 / 595880 nodes visited\n",
      "[184.397851] 300000 / 595880 nodes visited\n",
      "[184.533349] 310000 / 595880 nodes visited\n",
      "[184.669318] 320000 / 595880 nodes visited\n",
      "[184.802847] 330000 / 595880 nodes visited\n",
      "[184.941482] 340000 / 595880 nodes visited\n",
      "[185.078923] 350000 / 595880 nodes visited\n",
      "[185.212902] 360000 / 595880 nodes visited\n",
      "[185.352389] 370000 / 595880 nodes visited\n",
      "[185.489941] 380000 / 595880 nodes visited\n",
      "[185.632100] 390000 / 595880 nodes visited\n",
      "[185.772958] 400000 / 595880 nodes visited\n",
      "[185.919745] 410000 / 595880 nodes visited\n",
      "[186.058722] 420000 / 595880 nodes visited\n",
      "[186.199656] 430000 / 595880 nodes visited\n",
      "[186.344854] 440000 / 595880 nodes visited\n",
      "[186.485711] 450000 / 595880 nodes visited\n",
      "[186.627398] 460000 / 595880 nodes visited\n",
      "[186.771584] 470000 / 595880 nodes visited\n",
      "[186.909866] 480000 / 595880 nodes visited\n",
      "[187.048732] 490000 / 595880 nodes visited\n",
      "[187.192863] 500000 / 595880 nodes visited\n",
      "[187.332667] 510000 / 595880 nodes visited\n",
      "[187.473252] 520000 / 595880 nodes visited\n",
      "[187.610367] 530000 / 595880 nodes visited\n",
      "[187.744987] 540000 / 595880 nodes visited\n",
      "[187.887086] 550000 / 595880 nodes visited\n",
      "[188.001777] 560000 / 595880 nodes visited\n",
      "[188.118682] 570000 / 595880 nodes visited\n",
      "[188.232366] 580000 / 595880 nodes visited\n",
      "[188.341127] 590000 / 595880 nodes visited\n",
      "[188.431447] 600000 / 595880 nodes visited\n",
      "[188.464464] 610000 / 595880 nodes visited\n",
      "[188.482700] 620000 / 595880 nodes visited\n",
      "[188.485201] Concatenation...\n",
      "[188.501944] Renumbering nodes\n",
      "[188.501949] Initial node count 595880\n",
      "[188.506962] Removed 504069 null nodes\n",
      "[188.506970] Concatenation over!\n",
      "[188.506971] Clipping short tips off graph, drastic\n",
      "[188.537412] Concatenation...\n",
      "[188.573320] Renumbering nodes\n",
      "[188.573331] Initial node count 91811\n",
      "[188.576565] Removed 14019 null nodes\n",
      "[188.576570] Concatenation over!\n",
      "[188.576573] 77792 nodes left\n",
      "[188.576660] Writing into graph file data/tut02/assembly//Graph2...\n",
      "[190.055516] Measuring median coverage depth...\n",
      "[190.086099] Median coverage depth = 49.636559\n",
      "[190.086142] Removing contigs with coverage < 24.818280...\n",
      "[190.112921] Concatenation...\n",
      "[191.004597] Renumbering nodes\n",
      "[191.004612] Initial node count 77792\n",
      "[191.004807] Removed 76108 null nodes\n",
      "[191.004812] Concatenation over!\n",
      "[191.004871] Concatenation...\n",
      "[191.004991] Renumbering nodes\n",
      "[191.004996] Initial node count 1684\n",
      "[191.005000] Removed 0 null nodes\n",
      "[191.005008] Concatenation over!\n",
      "[191.005011] Clipping short tips off graph, drastic\n",
      "[191.005203] Concatenation...\n",
      "[191.006689] Renumbering nodes\n",
      "[191.006694] Initial node count 1684\n",
      "[191.006746] Removed 53 null nodes\n",
      "[191.006751] Concatenation over!\n",
      "[191.006753] 1631 nodes left\n",
      "[191.006757] Read coherency...\n",
      "[191.006787] Identifying unique nodes\n",
      "[191.006833] Done, 708 unique nodes counted\n",
      "[191.006837] Trimming read tips\n",
      "[191.006920] Renumbering nodes\n",
      "[191.006924] Initial node count 1631\n",
      "[191.006927] Removed 0 null nodes\n",
      "[191.006930] Confronted to 0 multiple hits and 0 null over 0\n",
      "[191.006933] Read coherency over!\n",
      "[191.011006] Starting pebble resolution...\n",
      "[191.016231] Computing read to node mapping array sizes\n",
      "[191.034670] Computing read to node mappings\n",
      "[191.192057] Estimating library insert lengths...\n",
      "[191.197228] Done\n",
      "[191.197262] Computing direct node to node mappings\n",
      "[191.225398] Scaffolding node 0\n",
      "[191.252406]  === Nodes Scaffolded in 0.055141 s\n",
      "[191.260555] Preparing to correct graph with cutoff 0.200000\n",
      "[191.335745] Cleaning memory\n",
      "[191.335756] Deactivating local correction settings\n",
      "[191.335779] Pebble done.\n",
      "[191.335783] Concatenation...\n",
      "[191.345750] Renumbering nodes\n",
      "[191.345757] Initial node count 1631\n",
      "[191.345801] Removed 517 null nodes\n",
      "[191.345812] Concatenation over!\n",
      "[191.345821] Removing reference contigs with coverage < 24.818280...\n",
      "[191.345874] Concatenation...\n",
      "[191.345931] Renumbering nodes\n",
      "[191.345935] Initial node count 1114\n",
      "[191.345939] Removed 0 null nodes\n",
      "[191.345948] Concatenation over!\n",
      "[191.350841] Writing contigs into data/tut02/assembly//contigs.fa...\n",
      "[191.886304] Writing into stats file data/tut02/assembly//stats.txt...\n",
      "[191.895806] Writing into graph file data/tut02/assembly//LastGraph...\n",
      "[192.599347] Writing into AMOS file data/tut02/assembly//velvet_asm.afg...\n",
      "[200.912746] Estimated Coverage = 49.636559\n",
      "[200.912766] Estimated Coverage cutoff = 24.818280\n",
      "Final graph has 1114 nodes and n50 of 20504, max 110187, total 4546063, using 1253389/1257935 reads\n"
     ]
    }
   ],
   "source": [
    "!velvetg data/tut02/assembly/ -scaffolding no -read_trkg yes -amos_file yes -exp_cov auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the actual command that assembles our reads into contigs. The flags are just some recommended settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our contigs, let's run a BLAST search to find out where our reads came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLASTN 2.6.0+\n",
      "\n",
      "\n",
      "Reference: Zheng Zhang, Scott Schwartz, Lukas Wagner, and Webb\n",
      "Miller (2000), \"A greedy algorithm for aligning DNA sequences\", J\n",
      "Comput Biol 2000; 7(1-2):203-14.\n",
      "\n",
      "\n",
      "\n",
      "Database: Nucleotide collection (nt)\n",
      "           50,405,971 sequences; 198,157,098,033 total letters\n",
      "\n",
      "\n",
      "\n",
      "Query= NODE_1_length_6431_cov_50.828331\n",
      "\n",
      "Length=6461\n",
      "\n",
      "RID: 5R5J2HR0016\n",
      "                                                                      Score     E\n",
      "Sequences producing significant alignments:                          (Bits)  Value\n",
      "\n",
      "CP034953.1  Escherichia coli strain MT102 chromosome, complete ge...  11926   0.0  \n",
      "CP034595.1  Escherichia coli strain WCHEC035053S1G0 chromosome, c...  11926   0.0  \n",
      "LR134083.1  Escherichia coli strain NCTC12655 genome assembly, ch...  11926   0.0  \n",
      "CP034426.1  Escherichia coli strain WPB121 chromosome                 11926   0.0  \n",
      "CP034428.1  Escherichia coli strain WPB102 chromosome                 11926   0.0  \n",
      "CP032667.1  Escherichia coli str. K-12 substr. MG1655 chromosome,...  11926   0.0  \n",
      "CP031214.1  Escherichia coli strain C600 chromosome, complete genome  11926   0.0  \n",
      "CP028704.1  Escherichia coli strain VH1 chromosome, complete genome   11926   0.0  \n",
      "CP028702.1  Escherichia coli strain J53 chromosome, complete genome   11926   0.0  \n",
      "CP027060.1  Escherichia coli str. K-12 substr. MG1655 strain K-12...  11926   0.0  \n",
      "CP026612.1  Escherichia coli strain DTU-1 chromosome, complete ge...  11926   0.0  \n",
      "CP026358.1  Escherichia coli strain 2A chromosome, complete genome    11926   0.0  \n",
      "CP026361.1  Escherichia coli strain 1A chromosome, complete genome    11926   0.0  \n",
      "CP026357.1  Escherichia coli strain 2F_0 chromosome, complete genome  11926   0.0  \n",
      "CP026352.1  Escherichia coli strain 4FA chromosome, complete genome   11926   0.0  \n",
      "CP026353.1  Escherichia coli strain 4A chromosome, complete genome    11926   0.0  \n",
      "CP026351.1  Escherichia coli strain 5A chromosome, complete genome    11926   0.0  \n",
      "CP026360.1  Escherichia coli strain 1FA chromosome, complete genome   11926   0.0  \n",
      "CP026354.1  Escherichia coli strain 3FA chromosome, complete genome   11926   0.0  \n",
      "CP026345.1  Escherichia coli strain 8A chromosome, complete genome    11926   0.0  \n",
      "CP026350.1  Escherichia coli strain 5FA chromosome, complete genome   11926   0.0  \n",
      "CP026347.1  Escherichia coli strain 7A chromosome, complete genome    11926   0.0  \n",
      "CP026346.1  Escherichia coli strain 7FA chromosome, complete genome   11926   0.0  \n",
      "CP026342.1  Escherichia coli strain 9FA chromosome, complete genome   11926   0.0  \n",
      "CP026343.1  Escherichia coli strain 9A chromosome, complete genome    11926   0.0  \n",
      "CP026348.1  Escherichia coli strain 6FA chromosome, complete genome   11926   0.0  \n",
      "CP026349.1  Escherichia coli strain 6A chromosome, complete genome    11926   0.0  \n",
      "CP026359.1  Escherichia coli strain 2_0 chromosome, complete genome   11926   0.0  \n",
      "BLAST failed to write output\n"
     ]
    }
   ],
   "source": [
    "!blastn -query data/tut02/assembly/contigs.fa -remote -db nt -evalue 0.05| head -n 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that our contigs seem to match with different strains of E. coli. If we look very closely we can see that `K-12 substr. MG1655` appears twice. For our next tutorial, we're going to assume that our assembled contigs belong to this particular strain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3.0'>Section 3 - Visualizing our Assembly</a>\n",
    "\n",
    "If you are following this session from home you'll need to install these two programs.....\n",
    "\n",
    "- <a href=\"https://ics.hutton.ac.uk/tablet/\">Tablet</a>\n",
    "- <a href=\"https://rrwick.github.io/Bandage/\">Bandage</a>\n",
    "\n",
    "Both of These programs offer some different visualizations for the assembly we just made. Tablet let's us examine the k-mer overlap we developed from `raw_reads1.fastq` were overlapped to make our contigs, while Bandage let's us examine the order our raw reads were put together.\n",
    "\n",
    "To use Tablet you need to download the `velvet_asm.afg` file from the `data/tut02/assembly` directory (Just navigate, right-click and select Download if you're in Jupyter) and open it in Tablet. If you do this you should end up with a visualization like this...\n",
    "\n",
    "<img src='img/tut02/Tablet.PNG'></img>\n",
    "\n",
    "The left section shows a list of all your contigs, the upper right section shows you the amount of overlap for a given section and the bottom right shows you a visualiztion with your k-mer overlaps.\n",
    "\n",
    "To use Bandage you need to download the `LastGraph` file from the `data/tut02/assembly` directory and download it, just like before. Now we can open it up in Bandage. Once it's loaded up in Bandage, click on the button that says \"Draw Graph\" and you should end up with a visualization that looks like this....\n",
    "\n",
    "<img src='img/tut02/Bandage.PNG'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
